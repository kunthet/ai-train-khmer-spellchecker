#!/usr/bin/env python3
"""
Demo Script for Syllable Filtering Enhancement

This script demonstrates the new filtering capabilities that categorize
and optionally filter non-Khmer syllables from frequency analysis.
"""

import logging
import sys
from pathlib import Path

# Add the project root to Python path
sys.path.insert(0, str(Path(__file__).parent))

from word_cluster.syllable_frequency_analyzer import SyllableFrequencyAnalyzer, SegmentationMethod


def setup_logging():
    """Setup basic logging"""
    logging.basicConfig(level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')


def test_filtering_comparison():
    """Compare analysis with and without filtering"""
    print("ğŸ” SYLLABLE FILTERING COMPARISON DEMO")
    print("=" * 50)
    
    # Sample texts with mixed content
    test_texts = [
        "á“áŸáŸ‡á‡á¶á€á¶ášáŸá¶á€á›áŸ’á”á„á¢ááŸ’áá”á‘ááŸ’á˜áŸ‚ášáŸ”",
        "VOA Khmer News ášá¶á™á€á¶ášááŸááŸ’á˜á¸áŸ”",
        "á”áŸ’ášá‘áŸáŸá€á˜áŸ’á–á»á‡á¶ Cambodia áŸ¢áŸ áŸ¢áŸ¥áŸ”",
        "Hello world á“á·á„ á—á¶áŸá¶ááŸ’á˜áŸ‚áš áŸ¡áŸ¢áŸ£áŸ”",
        "Phnom Penh á—áŸ’á“áŸ†á–áŸá‰ Capital CityáŸ”",
        "Reuters/BBC News á–áŸááŸŒá˜á¶á“á¢á“áŸ’áášá‡á¶áá·áŸ”",
        "á¢áŸ’á“á€áŸá¶ášá–áŸááŸŒá˜á¶á“ journalists reporting á€á¶ášá–áŸ’ášá¹ááŸ’áá·á€á¶ášááŸáŸ”"
    ]
    
    print(f"ğŸ“ Test texts ({len(test_texts)} samples):")
    for i, text in enumerate(test_texts, 1):
        print(f"  {i}. {text}")
    print()
    
    # Test WITHOUT filtering
    print("ğŸš« ANALYSIS WITHOUT FILTERING")
    print("-" * 35)
    
    analyzer_no_filter = SyllableFrequencyAnalyzer(
        filter_non_khmer=False,
        keep_punctuation=True
    )
    
    stats_no_filter = analyzer_no_filter.train_on_texts(test_texts, show_progress=False)
    
    print(f"Total syllables: {stats_no_filter.total_syllables}")
    print(f"Unique syllables: {stats_no_filter.unique_syllables}")
    print("Top 10 syllables:")
    for i, (syll, freq) in enumerate(stats_no_filter.most_common_syllables[:10], 1):
        syll_type = analyzer_no_filter._classify_syllable(syll)
        type_emoji = {"khmer": "ğŸ‡°ğŸ‡­", "mixed": "ğŸ”„", "punctuation": "ğŸ“", "non_khmer": "ğŸŒ"}.get(syll_type, "â“")
        print(f"  {i:2d}. '{syll}' {type_emoji}: {freq}")
    
    # Test WITH filtering
    print(f"\nâœ… ANALYSIS WITH FILTERING")
    print("-" * 33)
    
    analyzer_with_filter = SyllableFrequencyAnalyzer(
        filter_non_khmer=True,
        keep_punctuation=True,
        min_khmer_ratio=0.5
    )
    
    stats_with_filter = analyzer_with_filter.train_on_texts(test_texts, show_progress=False)
    
    print(f"Total syllables: {stats_with_filter.total_syllables}")
    print(f"Unique syllables: {stats_with_filter.unique_syllables}")
    print("Top 10 syllables:")
    for i, (syll, freq) in enumerate(stats_with_filter.most_common_syllables[:10], 1):
        syll_type = analyzer_with_filter._classify_syllable(syll)
        type_emoji = {"khmer": "ğŸ‡°ğŸ‡­", "mixed": "ğŸ”„", "punctuation": "ğŸ“", "non_khmer": "ğŸŒ"}.get(syll_type, "â“")
        print(f"  {i:2d}. '{syll}' {type_emoji}: {freq}")
    
    # Comparison summary
    print(f"\nğŸ“Š FILTERING IMPACT SUMMARY")
    print("-" * 29)
    reduction_total = stats_no_filter.total_syllables - stats_with_filter.total_syllables
    reduction_unique = stats_no_filter.unique_syllables - stats_with_filter.unique_syllables
    
    print(f"Total syllables reduced: {reduction_total} ({reduction_total/stats_no_filter.total_syllables:.1%})")
    print(f"Unique syllables reduced: {reduction_unique} ({reduction_unique/stats_no_filter.unique_syllables:.1%})")
    
    # Show categorization breakdown
    print(f"\nğŸ“Š SYLLABLE CATEGORIZATION")
    print("-" * 26)
    print(f"ğŸ‡°ğŸ‡­ Pure Khmer: {sum(analyzer_with_filter.khmer_syllable_frequencies.values())}")
    print(f"ğŸ”„ Mixed content: {sum(analyzer_with_filter.mixed_syllable_frequencies.values())}")
    print(f"ğŸ“ Punctuation: {sum(analyzer_with_filter.punctuation_frequencies.values())}")
    print(f"ğŸŒ Non-Khmer (filtered): {sum(analyzer_with_filter.non_khmer_syllable_frequencies.values())}")
    
    return analyzer_with_filter


def test_different_filter_settings():
    """Test different filtering configurations"""
    print(f"\nğŸ›ï¸  FILTERING CONFIGURATION TEST")
    print("=" * 35)
    
    test_texts = [
        "VOA Khmer News ášá¶á™á€á¶ášááŸááŸ’á˜á¸áŸ”",
        "á”áŸ’ášá‘áŸáŸá€á˜áŸ’á–á»á‡á¶ Cambodia áŸ¢áŸ áŸ¢áŸ¥áŸ”",
        "Hello world á“á·á„ á—á¶áŸá¶ááŸ’á˜áŸ‚áš áŸ¡áŸ¢áŸ£áŸ”"
    ]
    
    configs = [
        {"name": "Strict Khmer Only", "filter_non_khmer": True, "keep_punctuation": False, "min_khmer_ratio": 0.8},
        {"name": "Khmer + Punctuation", "filter_non_khmer": True, "keep_punctuation": True, "min_khmer_ratio": 0.8},
        {"name": "Khmer + Mixed Content", "filter_non_khmer": True, "keep_punctuation": True, "min_khmer_ratio": 0.3},
        {"name": "No Filtering", "filter_non_khmer": False, "keep_punctuation": True, "min_khmer_ratio": 0.0}
    ]
    
    for config in configs:
        print(f"\n{config['name']}:")
        print(f"  Settings: filter_non_khmer={config['filter_non_khmer']}, keep_punctuation={config['keep_punctuation']}, min_khmer_ratio={config['min_khmer_ratio']}")
        
        analyzer = SyllableFrequencyAnalyzer(
            filter_non_khmer=config["filter_non_khmer"],
            keep_punctuation=config["keep_punctuation"],
            min_khmer_ratio=config["min_khmer_ratio"]
        )
        
        stats = analyzer.train_on_texts(test_texts, show_progress=False)
        print(f"  Result: {stats.total_syllables} total, {stats.unique_syllables} unique syllables")


def test_syllable_validation_with_filtering():
    """Test syllable validation with filtering"""
    print(f"\nğŸ§ª SYLLABLE VALIDATION WITH FILTERING")
    print("=" * 40)
    
    # Train on Khmer texts
    training_texts = [
        "á“áŸáŸ‡á‡á¶á€á¶ášáŸá¶á€á›áŸ’á”á„á¢ááŸ’áá”á‘ááŸ’á˜áŸ‚ášáŸ”",
        "ááŸ’á‰á»áŸ†áŸáŸ’ášá›á¶á‰áŸ‹á—á¶áŸá¶ááŸ’á˜áŸ‚ášáá¶áŸáŸ‹áŸ”",
        "á”áŸ’ášá‘áŸáŸá€á˜áŸ’á–á»á‡á¶á˜á¶á“á‘á¸ášáŠáŸ’á‹á’á¶á“á¸á—áŸ’á“áŸ†á–áŸá‰áŸ”"
    ]
    
    analyzer = SyllableFrequencyAnalyzer(filter_non_khmer=True, keep_punctuation=True)
    analyzer.train_on_texts(training_texts, show_progress=False)
    
    # Test validation on mixed content
    test_syllables = [
        "á“áŸáŸ‡",        # Khmer - should be valid
        "á€á¶áš",        # Khmer - should be valid  
        "Hello",      # English - should be unknown
        "áŸ¢áŸ áŸ¢áŸ¥",      # Khmer numbers - should be valid/mixed
        "áŸ”",          # Khmer punctuation - depends on settings
        "VOA",        # English acronym - should be unknown
        "á—áŸ’á“áŸ†á–áŸá‰",     # Khmer compound - should be valid
        "123"         # Numbers - should be unknown
    ]
    
    print("Validation results:")
    for syllable in test_syllables:
        validation = analyzer.validate_syllable(syllable)
        syll_type = analyzer._classify_syllable(syllable)
        type_emoji = {"khmer": "ğŸ‡°ğŸ‡­", "mixed": "ğŸ”„", "punctuation": "ğŸ“", "non_khmer": "ğŸŒ"}.get(syll_type, "â“")
        
        print(f"  '{syllable}' {type_emoji}: {validation.rarity_level} (freq: {validation.frequency}, confidence: {validation.confidence_score:.2f})")


def generate_full_report():
    """Generate comprehensive filtering report"""
    print(f"\nğŸ“‹ COMPREHENSIVE FILTERING REPORT")
    print("=" * 35)
    
    # Use diverse test corpus
    test_texts = [
        "á“áŸáŸ‡á‡á¶á€á¶ášáŸá¶á€á›áŸ’á”á„á¢ááŸ’áá”á‘ááŸ’á˜áŸ‚ášáŠáŸá–á·áŸáŸáŸáŸ”",
        "VOA Khmer News á“á·á„ BBC Khmer á•áŸ’áŸá¶á™á–áŸááŸŒá˜á¶á“áŸ”",
        "á€á¶ášá”áŸ’ášá€á½áá”á¶á›áŸ‹á‘á¶ááŸ‹ World Cup áŸ¢áŸ áŸ¢áŸ¦ á“á¹á„á’áŸ’áœá¾á¡á¾á„áŸ”",
        "Facebook, Instagram á“á·á„ TikTok á–áŸá‰á“á·á™á˜áŸ”",
        "á€á˜áŸ’á˜áœá·á’á¸ AI (Artificial Intelligence) á€áŸ†á–á»á„á¢á—á·áœáŒáŸ’ááŸ”",
        "á‘á¸á€áŸ’ášá»á„á—áŸ’á“áŸ†á–áŸá‰ Phnom Penh Capital City ášá”áŸáŸ‹á€á˜áŸ’á–á»á‡á¶áŸ”",
        "áŸá¶á€á›áœá·á‘áŸ’á™á¶á›áŸá™ Harvard University á“á·á„ MIT á›áŸ’á”á¸á›áŸ’á”á¶á‰áŸ”",
        "á€á¶ášá”á„áŸ’á€á¶ášá‡áŸ†á„áº COVID-19 á“áŸ…ááŸ‚á”á“áŸ’ááŸ”"
    ]
    
    analyzer = SyllableFrequencyAnalyzer(
        filter_non_khmer=True,
        keep_punctuation=True,
        min_khmer_ratio=0.3  # Allow some mixed content
    )
    
    stats = analyzer.train_on_texts(test_texts, show_progress=False)
    
    # Generate and display full report
    report = analyzer.generate_report()
    print(report)
    
    return analyzer


def main():
    """Main demo function"""
    setup_logging()
    
    print("ğŸ¯ SYLLABLE FILTERING ENHANCEMENT DEMO")
    print("=" * 45)
    print("Testing filtering capabilities for better Khmer spellchecker models")
    print()
    
    try:
        # Run all tests
        analyzer = test_filtering_comparison()
        test_different_filter_settings()
        test_syllable_validation_with_filtering()
        final_analyzer = generate_full_report()
        
        print(f"\nğŸ‰ FILTERING DEMO COMPLETED SUCCESSFULLY!")
        
        print(f"\nğŸ“‹ Key Benefits of Filtering:")
        print("   âœ… Cleaner Khmer language models")
        print("   âœ… Better frequency statistics for spellchecking")
        print("   âœ… Reduced noise from mixed-language content")
        print("   âœ… Configurable filtering levels for different use cases")
        print("   âœ… Preserved context information for legitimate mixed content")
        
        print(f"\nğŸ”§ Recommended Settings for Production:")
        print("   â€¢ filter_non_khmer=True (enable filtering)")
        print("   â€¢ keep_punctuation=True (preserve context)")
        print("   â€¢ min_khmer_ratio=0.3 (allow some mixed content)")
        print("   â€¢ Filters out pure English/numbers while keeping Khmer-dominant content")
        
        # Save the filtered model
        print(f"\nğŸ’¾ Saving filtered frequency model...")
        output_dir = Path("output/filtered_models")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        model_path = output_dir / "khmer_filtered_frequency_model"
        final_analyzer.save_frequency_data(str(model_path))
        print(f"   Model saved to: {model_path}.json/.pkl")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        raise


if __name__ == "__main__":
    main() 